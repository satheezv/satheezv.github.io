---
title: "PREVENT: Proactive Risk Evaluation and Vigilant Execution of Navigation and Manipulation Tasks for Mobile Robot Chemists"
collection: publications
category: manuscripts
permalink: 
excerpt: 'we propose navigation and manipulation skills based on a multimodal Behavior Tree (BT) approach that can be integrated into existing software architectures with minimal modifications. Our approach involves a hierarchical perception mechanism that exploits AI techniques (CNNs and VLMs) and sensory feedback through Dexterous Vision and Navigational Vision cameras and an IoT gas sensor module for execution-related decision-making.'
date: 2025-01-01
venue: 'Robotics and Automation Letters (Submitted)'
paperurl: 'TBC'
citation: 'Satheeshkumar Veeramani, Zhengxue Zhou, Francisco Munguia-Galeano, Hatem Fakhruldeen, Thomas Roddelkopf, Mohammed Faeik Ruzaij Al-Okby, Kerstin Thurow, Andrew Ian Cooper" (2025).'
---
Mobile robotic chemists are a fast growing trend in the field of chemistry and materials research. However, so far these mobile robots lack workflow awareness skills. This poses the risk that even a small anomaly, such as an improperly capped sample vial could disrupt the entire workflow. This wastes time, and resources, and could pose risks to human researchers, such as exposure to toxic materials. Unimodal perception mechanisms can be used to predict anomalies but they often generate excessive false positives. This may halt workflow execution unnecessarily, requiring researchers to intervene and to resume the workflow when no problem actually exists, negating the benefits of autonomous operation. To address this problem, we propose navigation and manipulation skills based on a multimodal Behavior Tree (BT) approach that can be integrated into existing software architectures with minimal modifications. Our approach involves a hierarchical perception mechanism that exploits AI techniques (CNNs and VLMs) and sensory feedback through Dexterous Vision and Navigational Vision cameras and an IoT gas sensor module for execution-related decision-making. Experimental evaluations show that the proposed approach is comparatively efficient and completely avoids both false negatives and false positives when tested in simulated risk scenarios within our robotic chemistry workflow. The results also show that the proposed multi-modal perception skills achieved deployment accuracies that were higher than the average of the corresponding uni-modal skills, both for navigation and for manipulation.

<!-- Video Frame -->
<div style="margin-top: 2em;">
  <h3>Video Demonstration - YT</h3>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/ltLH8v6l0pY?si=Lm1CftqjJwA0jxv8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

<div style="margin-top: 2em;">
  <h3>Video Demonstration - onedrive</h3>
    <iframe src="https://1drv.ms/v/c/cf51dbc58b2a1fcd/IQQdPa8PmSQETaHZGfZzFzyfAYvltJ5SwameaSfs9rAHixM" width="1920" height="1080" frameborder="0" scrolling="no" allowfullscreen></iframe>
</div>